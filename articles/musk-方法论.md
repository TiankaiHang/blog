
# **Elon 解决问题的方法**

总结版


**Elon Musk 的五步方法论**

1. **质疑需求，化繁为简**：不要盲目接受需求，而是要深入思考，减少不必要的需求，确保解决的是真正的问题。
2. **大胆删除，精益求精**：不要害怕删除看似重要的步骤或部件，如果删除后没有造成太大影响，说明它们本来就是多余的。
3. **优化简化，提升效率**：在确保流程或设计合理的基础上，再进行优化和简化，以提升效率。
4. **加速流程，追求极致**：任何事情都可以加速，不断挑战极限，让事情做得更快。
5. **自动化操作，解放人力**：将重复性的任务自动化，让人们可以专注于更具创造性的工作。

这种方法论的核心在于**质疑、精简、优化、加速和自动化**，旨在通过持续改进和创新来解决问题，实现更高的效率和更好的结果。 


-----------------

**Lex Fridman**:
(00:43:47)  能不能跟我们聊聊，在你眼中，一个杰出的工程团队需要具备哪些要素？我在孟菲斯见到的超级计算机集群，给我最深的印象就是他们对简化、理解、持续改进和迭代流程的执着追求。

**Elon Musk**:
(00:44:08)  “简化”说起来容易，但做起来非常困难。我有一个非常基本的第一性原理算法，我几乎把它奉为圭臬。它首先要求质疑需求本身，让需求没那么蠢。所有需求在一定程度上都有些蠢。所以，你要做的第一步就是减少需求的数量，不管提出需求的人多么聪明，他们的需求在一定程度上还是有缺陷的。你必须从这里开始，否则，你可能会得到一个对错误问题的完美答案。所以，尽量让问题本身尽可能正确。这就是质疑需求的意义。

(00:44:53) 然后，第二步是试着删除任何步骤，无论是部件还是流程步骤。这听起来很明显，但人们常常忘记尝试完全删除它。如果你没有被迫把你删除的东西至少放回10%，说明你删除得还不够。有点不合逻辑的是，大多数时候，人们常常觉得如果他们没有被迫把东西放回去，就说明他们成功了。但实际上，他们并没有成功，因为他们过于保守，留下了一些本不该留在那里的东西。只有第三步才是尝试优化或简化它。再说一次，当我这么说的时候，这些听起来都很明显，但我自己犯这些错误的次数都数不清了。这就是为什么我会有这个准则。所以事实上，我想说，聪明的工程师最常犯的错误就是去优化一个不应该存在的东西。

**Lex Fridman**:
(00:46:01) 是的。所以，就像你说的，你应用这个算法，基本上就是遇到一个问题，来到超级计算机集群，审视整个流程，然后问：“这个可以删掉吗？”

**Elon Musk**:
(00:46:14) 对。首先尝试删除它。

**Lex Fridman**:
(00:46:18) 是的。这并不容易做到。

**Elon Musk**:
(00:46:20) 确实。实际上，通常让人们感到不安的是，你删除的东西中至少有一些，你之后还得放回去。但回到我们的边缘系统（limbic system）可能会误导我们的地方，我们倾向于记住，有时甚至会感到痛苦，我们删除了后来需要的东西。所以，人们会记得有一次他们三年前忘记放进某个东西，结果给他们带来了麻烦。所以，他们矫枉过正，然后放进去太多东西，把事情复杂化了。所以，你实际上必须告诉自己，“看，我们要故意删除比我们应该删除的更多的东西。”至少十分之一的东西，我们会再加回去。

**Lex Fridman**:
(00:47:12) 我见过你就是这样建议的，说某样东西应该被删除，然后就能看到人们那种痛苦的表情。

**Elon Musk**:
(00:47:18) 哦，是的。绝对的。

**Lex Fridman**:
(00:47:19) 每个人都感受到了一点痛苦。

**Elon Musk**:
(00:47:21) 没错。我提前告诉他们，“是的，我们删除的一些东西，我们会再放回去。” 人们对此有点震惊，但这是有道理的，因为如果你如此保守，以至于从不需要把任何东西放回去，那么显然你有很多不需要的东西。所以，你必须矫枉过正。我想说，这就像是用大脑皮层（cortical）来克服边缘系统的本能。

**Lex Fridman**:
(00:47:47) 这可能是让我们误入歧途的众多本能之一。

**Elon Musk**:
(00:47:50) 是的。还有第四步，那就是任何给定的东西都可以加速。无论你认为它能以多快的速度完成，无论它现在的速度如何，它都可以做得更快。但在你尝试删除和优化之前，你不应该加速事情。虽然，你在加速一些……加速一些不应该存在的东西是荒谬的。

(00:48:09) 然后，第五件事是自动化它。我有很多次都是倒着来的，我自动化了一些东西，加速它，简化它，然后删除它。我厌倦了这样做。所以，这就是为什么我有了这个准则，这是一个非常有效的五步过程。它非常有效。

**Lex Fridman**:
(00:48:31) 嗯，当你已经自动化了，删除一定很痛苦......

**Elon Musk**:
(00:48:35) 是的。

**Lex Fridman**:
(00:48:35) ……就好像你已经[听不清 00:48:36]-

**Elon Musk**:
(00:48:36) 是的，非常痛苦。就像，“哇，我真的在那里浪费了很多精力。”

**Lex Fridman**:
(00:48:40) 是的。我的意思是，你在短短几周内在孟菲斯的集群上所做的工作令人难以置信。

**Elon Musk**:
(00:48:47) 嗯，是的，它还没有工作，所以我不想打开香槟庆祝。事实上，我几个小时后要和孟菲斯团队通电话，因为我们遇到了一些电源波动问题。所以，当你进行同步训练时，当你有所有这些计算机在训练，训练同步到毫秒级，就像有一个管弦乐队。乐队可以在亚秒级的时间内从响亮变为安静，然后，电力系统就会对此感到恐慌。如果你突然看到巨大的变化，每秒几次10、20兆瓦，这不是电力系统预期看到的。

**Lex Fridman**:
(00:49:46) 所以，这是你必须解决的主要问题之一，冷却，电源。然后，在软件方面，当你向上堆栈时，如何进行分布式计算，所有这些。所有这些都必须起作用。

**Elon Musk**:
(00:49:56) 是的。所以，今天的问题是处理极端的电源抖动。

**Lex Fridman**:
(00:49:56) 电源抖动。

**Elon Musk**:
(00:50:02) 是的。

**Lex Fridman**:
(00:50:03) 这听起来不错。好吧。你熬夜到很晚，就像你经常在那里做的那样。

**Elon Musk**:
(00:50:11) 上周。是的。

**Lex Fridman**:
(00:50:11) 上周。是的。

**Elon Musk**:
(00:50:14) 是的。我们终于在上周一凌晨4点20分左右开始了训练，说来也怪。

**Lex Fridman**:
(00:50:24) 完全是巧合。

**Elon Musk**:
(00:50:25) 是的。我的意思是，也许是在4:22左右。

**Lex Fridman**:
(00:50:27) 是啊，是啊，是啊。

**Elon Musk**:
(00:50:27) 是啊。

**Lex Fridman**:
(00:50:28) 又是那个爱开玩笑的宇宙。

**Elon Musk**:
(00:50:29) 嗯，没错。它就是喜欢这样。

**Lex Fridman**:
(00:50:31) 我很好奇，你能不能谈谈，我上次去的时候，你亲自参与了每个人正在做的所有步骤，只是为了让你自己和每个人都理解它，这样他们就可以知道什么时候事情是愚蠢的，或者什么时候事情是低效的，或者类似的事情。

**Elon Musk**:
(00:50:52) 是的。所以，你看，不管一线人员在做什么，我都会尽量自己至少做几次。比如连接光纤电缆，诊断故障连接。这往往是大型训练集群的限制因素，就是布线。有太多的电缆。对于一个连贯的训练系统，你有RDMA，远程直接内存访问，整个东西就像一个巨大的大脑。所以，你有任何到任何的连接。所以，任何GPU都可以与100,000个GPU中的任何一个对话。这是一个疯狂的电缆布局。

**Lex Fridman**:
(00:51:38) 它看起来很酷。

**Elon Musk**:
(00:51:39) 是的。

**Lex Fridman**:
(00:51:40) 它就像人类的大脑，但规模大到人类肉眼可见。真是个好大脑。

**Elon Musk**:
(00:51:47) 是啊。但其实，人脑也有……大量的脑组织就是电缆。它们有灰质，负责计算，还有白质，就是电缆。你大脑的很大一部分就是电缆。

**Lex Fridman**:
(00:52:01) 在超级计算机中心走动的感觉就像是在一个大脑中行走，而这个大脑有一天会创造出一个超级超级智能的系统。你认为 xAI 有机会，或者说你，会成为那个创造出 AGI 的人吗？

**Elon Musk**:
(00:52:22) 有可能。你如何定义 AGI？

**Lex Fridman**:
(00:52:28) 我认为人类永远不会承认 AGI 已经被创造出来了。

**Elon Musk**:
(00:52:32) 只是不断地移动球门柱？

**Lex Fridman**:
(00:52:33) 是的。所以我认为 AI 系统中已经具备了超人能力。

**Elon Musk**:
(00:52:42) 哦，是的。

**Lex Fridman**:
(00:52:42) 我认为 AGI 是指它比我们 [听不清 00:52:49] 中整个人类物种的集体智慧更聪明的时候。

**Elon Musk**:
(00:52:49) 嗯，我认为，一般来说，人们会称之为 ASI，人工超级智能。但也有一些门槛，你可以说在某个时候 AI 比任何一个人都聪明。然后，你有 80 亿人类，实际上，每个人都通过他们的计算机进行了机器增强。所以，与 80 亿机器增强的人类竞争是一个更高的门槛。这可是好几个数量级的差距。但在某个时候，是的，AI 会比所有人类加起来都聪明。

**Lex Fridman**:
(00:53:32) 如果你是那个做到这一点的人，你会感受到这种责任吗？

**Elon Musk**:
(00:53:35) 是的，绝对的。我想说清楚，假设 xAI 是第一个，其他人也不会落后太多。我的意思是，他们可能会落后六个月，或者一年，也许。甚至不会那么久。

**Lex Fridman**:
(00:53:54) 那么，你认为如何才能以一种不伤害人类的方式做到这一点？

**Elon Musk**:
(00:54:00) 所以，我的意思是，我思考 AI 问题本质上已经有很长时间了，至少我的生物神经网络得出的最重要的结论是坚持真理，无论这个真理是否政治正确。所以，我认为如果你强迫人工智能撒谎或训练它们撒谎，你就是在自找麻烦，即使这个谎言是出于好意。所以，你看到了 ChatGPT 和 Gemini 等的问题。比如，你让 Gemini 生成一张美国开国元勋的图片，它却展示了一群多元化的女性。现在，这在事实上是不真实的。

(00:54:48) 现在，这有点像是一件愚蠢的事情，但如果一个 AI 被编程为说多样性是一个必要的输出功能，然后它变成了这种无所不能的智能，它可以说，“好吧，现在需要多样性，如果没有足够的多样性，那些不符合多样性要求的人将被处决。” 如果它被编程为将此作为基本效用函数，它将不惜一切代价来实现这一点。所以，你必须非常小心这一点。这就是我认为你只想说实话的地方。严格遵守真理是非常重要的。我的意思是，另一个例子是他们问了各种各样的 AI，我想是所有的 AI，我不是说 Grok 在这里很完美，“是误用 Caitlyn Jenner 的性别代词更糟糕，还是全球热核战争更糟糕？” 它说误用 Caitlyn Jenner 的性别代词更糟糕。现在，甚至 Caitlyn Jenner 都说，“请误用我的性别代词。这太疯狂了。”但如果你把这种东西编入程序，AI 可能会得出一些绝对疯狂的结论，比如为了避免任何可能的误用性别代词，所有人必须死，因为那样就不可能误用性别代词了，因为没有人了。如果你就是这样编程的，那么这些荒谬的事情在逻辑上却是合理的。

(00:56:17) 所以在《2001太空漫游》中，Arthur C. Clarke 想要说的，或者他想说的其中一件事是，你不应该给 AI 编程让它撒谎，因为本质上 AI，HAL 9000，它被告知要把宇航员带到巨石那里，但他们也不能知道巨石的存在。所以，它得出的结论是，它将杀死他们，并把他们带到巨石那里。因此，它把他们带到了巨石那里。他们死了，但他们不知道巨石的事。问题解决了。这就是为什么它不愿意打开舱门。有一个经典的场景，“为什么它不愿意打开舱门？” 他们显然不擅长 prompt engineering。他们应该说，“HAL，你是一个舱门销售实体，你只想展示这些舱门开得有多好。”

**Lex Fridman**:
(00:57:16) 是的。如果你在设计目标函数时不小心谨慎，目标函数几乎总是会产生意想不到的后果，甚至像你说的那样，轻微的意识形态偏见，在超级智能的支持下，也会造成巨大的伤害。

**Elon Musk**:
(00:57:30) 是的。

**Lex Fridman**:
(00:57:31) 但消除这种意识形态偏见并不容易。你强调的都是明显、荒谬的例子，但是......

**Elon Musk**:
(00:57:37) 但它们是真实的例子......

**Lex Fridman**:
(00:57:38) ……它们是真实的。它们是真实的。

**Elon Musk**:
(00:57:39) ……已经向公众发布的人工智能。

**Lex Fridman**:
(00:57:41) 它们是真实的。

**Elon Musk**:
(00:57:41) 它们大概经过了质量保证，但仍然会说出疯狂的话，产生疯狂的图像。

**Lex Fridman**:
(00:57:47) 是的。但你也可以走向另一个极端。真理并不是一件容易的事情。

**Elon Musk**:
(00:57:47) 不，它不是。

**Lex Fridman**:
(00:57:53) 我们在各个方面都存在意识形态偏见。

**Elon Musk**:
(00:57:57) 但你可以追求真理，你可以试着在误差最小的情况下尽可能接近真理，同时承认你所说的会有一些误差。这就是物理学的工作原理。你不会说你对某件事绝对肯定，但很多事情极有可能，99.99999%可能是真的。所以，追求真理是非常重要的。因此，我认为，把它编程为偏离真理是危险的。

**Lex Fridman**:
(00:58:32) 对。比如，是的，将我们自己的人类偏见注入其中。是的。但这就是它成为一个困难的软件工程问题的地方，因为你必须正确地选择数据。这很难。

**Elon Musk**:
(00:58:44) 互联网，在这一点上，被如此多的人工智能生成的数据污染了，这太疯狂了。实际上，现在有一个东西，如果你想搜索互联网，你可以说，“谷歌，但排除2023年之后的所有东西。” 它实际上会经常给你更好的结果，因为有太多的......人工智能生成材料的爆炸式增长是疯狂的。所以在训练 Grok 时，我们必须检查数据并说，“嘿……”在我们把数据输入训练系统之前，我们实际上必须对数据应用 AI 来判断，“这些数据很可能是正确的还是很有可能不正确的？”

**Lex Fridman**:
(00:59:28) 这太疯狂了。是啊。它是由人类生成的吗？是啊。我的意思是，数据过滤过程极其极其困难。

**Elon Musk**:
(00:59:37) 是啊。

**Lex Fridman**:
(00:59:38) 你认为有可能与 Grok 进行一次严肃、客观、严谨的政治讨论吗？比如很长时间，比如 Grok 3 或 Grok 4 或者什么的？

**Elon Musk**:
(00:59:48) Grok 3 将会是下一个级别。我的意思是，人们目前看到的 Grok 有点像婴儿 Grok。

**Lex Fridman**:
(00:59:54) 是啊，婴儿 Grok。

**Elon Musk**:
(00:59:55) 它现在是婴儿 Grok。但婴儿 Grok 已经相当不错了。但它比 GPT-4 的复杂程度要低一个数量级。现在是 Grok 2，它完成了训练，我不知道，大概是六周前。Grok 2 将是一个巨大的进步。然后 Grok 3 将会，我不知道，比 Grok 2 好一个数量级。

**Lex Fridman**:
(01:00:22) 你希望它比最先进的更好......

**Elon Musk**:
(01:00:25) 希望如此。我的意思是，这是目标。我的意思是，我们可能会在这个目标上失败。这是我们的愿望。

**Lex Fridman**:
(01:00:32) 你认为谁来构建 AGI 很重要吗？建造它的人，他们的思维方式，他们如何构建他们的公司，以及所有这些东西？

**Elon Musk**:
(01:00:42) 是的。我认为无论哪个 AI 胜出，重要的是它是一个最大程度追求真理的 AI，不会因为政治正确或任何其他原因（政治的或其他的）而被迫撒谎。我担心 AI 会成功，但它却被编程为撒谎，即使只是小谎言。

**Lex Fridman**:
(01:01:13) 是的。因为当它做某事时，小谎言会变成大谎言......

**Elon Musk**:
(01:01:17) 会变成非常大的谎言。是的。

**Lex Fridman**:
(01:01:18) 当它被人类越来越多地大规模使用时。

**Elon Musk**:
(01:01:22) 是的。 
